<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Local LangChain AI Demos</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }
    body {
      font-family: 'Georgia', 'Times New Roman', serif;
      line-height: 1.5;
      color: #2c2c2c;
      background: #fafafa;
      padding: 40px 20px;
    }
    .container {
      max-width: 800px;
      margin: 0 auto;
      background: white;
      padding: 50px;
      border: 1px solid #e0e0e0;
    }
    header {
      margin-bottom: 40px;
      border-bottom: 2px solid #000;
      padding-bottom: 20px;
    }
    h1 {
      font-size: 1.8em;
      font-weight: normal;
      margin-bottom: 8px;
      letter-spacing: -0.5px;
    }
    .tagline {
      font-size: 0.95em;
      color: #555;
      font-style: italic;
    }
    .demo-section {
      margin-bottom: 45px;
    }
    .demo-header {
      display: flex;
      align-items: baseline;
      gap: 12px;
      margin-bottom: 15px;
    }
    .demo-number {
      font-size: 0.9em;
      font-weight: bold;
      color: #666;
      min-width: 20px;
    }
    h2 {
      font-size: 1.3em;
      font-weight: normal;
      margin: 0;
      border-bottom: 1px solid #ccc;
      padding-bottom: 8px;
      flex-grow: 1;
    }
    .subtitle {
      font-size: 0.95em;
      color: #666;
      margin-bottom: 15px;
      font-style: italic;
      margin-left: 32px;
    }
    h3 {
      font-size: 0.95em;
      font-weight: bold;
      margin-top: 20px;
      margin-bottom: 10px;
      margin-left: 32px;
      text-transform: uppercase;
      letter-spacing: 0.5px;
      color: #444;
    }
    .content {
      margin-left: 32px;
      font-size: 0.95em;
      line-height: 1.6;
    }
    ul {
      list-style: none;
      padding: 0;
    }
    li {
      padding: 6px 0;
      padding-left: 20px;
      position: relative;
    }
    li:before {
      content: "â€¢";
      position: absolute;
      left: 0;
      color: #999;
    }
    .voice-player {
      background: #f5f5f5;
      padding: 18px;
      margin: 12px 0;
      border-left: 3px solid #000;
    }
    .voice-name {
      font-weight: bold;
      margin-bottom: 4px;
      font-size: 0.95em;
    }
    .voice-description {
      font-size: 0.9em;
      color: #666;
      margin-bottom: 10px;
      font-style: italic;
    }
    audio {
      width: 100%;
      max-width: 100%;
      margin-bottom: 8px;
      height: 28px;
    }
    audio::-webkit-media-controls-panel {
      background-color: #fff;
    }
    .download-link {
      color: #000;
      text-decoration: none;
      border-bottom: 1px solid #000;
      font-size: 0.9em;
    }
    .download-link:hover {
      background: #f0f0f0;
    }
    .note {
      background: #f9f9f9;
      border-left: 3px solid #999;
      padding: 12px 15px;
      margin: 15px 0;
      font-size: 0.9em;
      color: #555;
      margin-left: 32px;
    }
    .note strong {
      font-weight: bold;
    }
    footer {
      margin-top: 50px;
      padding-top: 20px;
      border-top: 1px solid #e0e0e0;
      text-align: center;
      font-size: 0.85em;
      color: #999;
    }
  </style>
</head>
<body>
  <div class="container">
    <header>
      <h1>Local LangChain AI Demos</h1>
      <p class="tagline">Production-ready examples showcasing local LLM applications with LangChain, LangGraph, Ollama, and vector databases</p>
    </header>

    <!-- Demo 1: Research Synthesizer -->
    <section class="demo-section">
      <div class="demo-header">
        <span class="demo-number">1.</span>
        <h2>Research Synthesizer Assistant</h2>
      </div>
      <p class="subtitle">AI-powered research assistant that synthesizes comprehensive answers from multiple sources</p>
      
      <h3>Features</h3>
      <div class="content">
        <ul>
          <li>Local Documents: Index and search PDFs/TXT files via FAISS vector database</li>
          <li>arXiv Papers: Automatic academic paper retrieval and analysis</li>
          <li>Web Search: Real-time information via Tavily API (optional)</li>
          <li>Smart RAG Pipeline: HuggingFace embeddings + cross-encoder reranking</li>
          <li>Modern UI: Gradio interface with collapsible sidebar and report management</li>
        </ul>
      </div>

      <h3>Tech Stack</h3>
      <div class="content">
        <ul>
          <li>LLM: Ollama (Qwen, Mistral) via LangChain/LangGraph</li>
          <li>Vector DB: FAISS with all-MiniLM-L6-v2 embeddings</li>
          <li>Reranking: Cross-encoder ms-marco-MiniLM-L-6-v2</li>
          <li>Interface: Gradio 6.1+</li>
        </ul>
      </div>

      <div class="note">
        <strong>Note:</strong> Research tool for educational purposes. Verify important information from primary sources.
      </div>
    </section>

    <!-- Demo 2: Piper TTS Voice Showcase -->
    <section class="demo-section">
      <div class="demo-header">
        <span class="demo-number">2.</span>
        <h2>Piper TTS Voice Showcase</h2>
      </div>
      <p class="subtitle">Interactive demo of 4 high-quality neural TTS voices with 904 LibriTTS speaker variants</p>

      <h3>Voice Samples</h3>
      
      <div class="content">
        <div class="voice-player">
          <div class="voice-name">Heather</div>
          <div class="voice-description">Natural, conversational female voice (medium quality)</div>
          <audio controls>
            <source src="../piper-tts-demo/wav/heather.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
          <p><a href="../piper-tts-demo/wav/heather.wav" class="download-link" download>Download heather.wav</a> (~500KB)</p>
        </div>

        <div class="voice-player">
          <div class="voice-name">Michael</div>
          <div class="voice-description">Balanced, natural male voice (medium quality)</div>
          <audio controls>
            <source src="../piper-tts-demo/wav/mike.wav" type="audio/wav">
            Your browser does not support the audio element.
          </audio>
          <p><a href="../piper-tts-demo/wav/mike.wav" class="download-link" download>Download mike.wav</a> (~500KB)</p>
        </div>
      </div>

      <h3>Highlights</h3>
      <div class="content">
        <ul>
          <li>4 voice models: Heather, Michael, Lessac, LibriTTS</li>
          <li>904 unique speakers in LibriTTS multi-speaker model</li>
          <li>Smart preprocessing: tables, citations, markdown cleanup</li>
          <li>Auto-generate and cache WAV files locally</li>
          <li>Table linearization for natural speech rendering</li>
          <li>Interactive player with voice and speaker selection</li>
        </ul>
      </div>

      <div class="note">
        <strong>Use Cases:</strong> Local TTS synthesis, voice comparison, accessibility tools, audio content generation
      </div>
    </section>

    <!-- Demo 3: Chatbot with Memory -->
    <section class="demo-section">
      <div class="demo-header">
        <span class="demo-number">3.</span>
        <h2>Chatbot Assistant with Persistent Memory</h2>
      </div>
      <p class="subtitle">Fully local, tool-enabled chatbot with session-isolated, persistent memory</p>

      <h3>Highlights</h3>
      <div class="content">
        <ul>
          <li>Persistent memory via LangGraph MemorySaver</li>
          <li>Tool calling: Wikipedia, Tavily, custom tools</li>
          <li>Local LLMs via Ollama (e.g., qwen2.5:3b)</li>
          <li>Gradio UI with session state</li>
          <li>Privacy-first, offline-capable</li>
        </ul>
      </div>

      <div class="note">
        <strong>Use Cases:</strong> Personal assistants, research bots, privacy-sensitive applications
      </div>
    </section>

    <!-- Demo 4: LangChain RAG -->
    <section class="demo-section">
      <div class="demo-header">
        <span class="demo-number">4.</span>
        <h2>LangChain RAG</h2>
      </div>
      <p class="subtitle">Lightweight Retrieval-Augmented Generation (RAG) pipeline for grounded question answering</p>

      <h3>Highlights</h3>
      <div class="content">
        <ul>
          <li>In-memory vector store with semantic search</li>
          <li>Automatic document chunking and embeddings</li>
          <li>Ollama-powered LLM (Mistral 7B)</li>
          <li>Single-turn and multi-turn chat modes</li>
          <li>Pluggable embeddings: HuggingFace or fallback</li>
        </ul>
      </div>

      <div class="note">
        <strong>Use Cases:</strong> Document Q&A, knowledge assistants, RAG prototyping
      </div>
    </section>

    <!-- Tech Stack Overview -->
    <section class="demo-section">
      <h3 style="margin-left: 0; margin-top: 0;">Core Tech Stack</h3>
      <div class="content">
        <ul>
          <li>LangChain (v1.0+)</li>
          <li>Ollama (local LLM inference)</li>
          <li>Gradio (chat UI)</li>
          <li>HuggingFace embeddings (optional)</li>
        </ul>
        <p style="margin-top: 15px; font-style: italic; color: #555;">
          <strong>Goal:</strong> Demonstrate clean, modern patterns for building local, private, LLM-powered systems with memory, tools, and retrieval.
        </p>
      </div>
    </section>

    <footer>
      <p>Local LangChain AI Demos | Production-ready examples for local LLM applications</p>
    </footer>
  </div>
</body>
</html>